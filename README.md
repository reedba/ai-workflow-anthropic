# ðŸ¤– AI Workflow Demonstrations Suite

A comprehensive collection of AI-powered workflow demonstrations showcasing docum### ðŸ§ª **Evaluator-Optimizer Workflow**
Advanced AI evaluation and optimization system:
1. **ðŸ§ª Test Case Creation**: Define input-output pairs for systematic AI testing
2. **ðŸ“Š Multi-Metric Assessment**: Evaluate accuracy, relevance, completeness, and clarity
3. **ðŸŽ¯ Systematic Optimization**: Test multiple prompt variations and parameter configurations
4. **ðŸ“ˆ Performance Analytics**: Track improvements and generate optimization recommendations

**Optimization Focus Areas**: Speed & Cost, Quality & Accuracy, Balanced Performance

### ðŸŽ­ **Orchestrator-Worker Workflow**
Distributed AI processing system with specialized workers:
1. **ðŸŽ­ Central Orchestrator**: Manages task distribution, priority queuing, and worker allocation
2. **ðŸ‘¥ Specialized Workers**: 7 AI workers handling different analysis types (Document Analysis, Sentiment, Translation, etc.)
3. **ðŸ“‹ Task Coordination**: Priority-based scheduling with concurrent processing capabilities
4. **ðŸ“Š Performance Monitoring**: Real-time worker statistics and system health tracking

**Worker Types**: Document Analyzer (2x), Sentiment Analyzer, Translator, Summarizer, Question Generator, Category Classifier

**Key Features**: Fault tolerance, load balancing, scalable architecture, distributed processingessing, intelligent routing, parallelization techniques, and orchestrator-worker patterns using OpenAI's API and Gradio interfaces.

## ðŸš€ Available Workflows

### ðŸ“„ **1. True Prompt Chaining & Document Processing**
**File**: `prompt_chaining.py` | **Port**: `7860`
- **Modular Architecture**: Each step is an independent, reusable method
- **4-Step Chain**: Summarize â†’ Extract Points â†’ Categorize â†’ Generate Insights
- **Composable Workflows**: Execute individual steps or full chains
- **Dependency Tracking**: Monitor step relationships and token usage
- **Production-Ready**: Proper error handling and observability

### ðŸŽ¯ **2. AI-Powered Request Routing**
**File**: `routing.py` | **Port**: `7861`
- **Intelligent Classification**: 8 specialized routing categories
- **Priority Assessment**: Automatic urgency detection with SLA management
- **Veterans Affairs Support**: Specialized VA claims and appeals routing
- **Action Planning**: Detailed routing summaries with next steps

### âš¡ **3. AI Parallelization Demo**
**File**: `parallelization.py` | **Port**: `7862`
- **Performance Comparison**: Sequential vs Parallel processing
- **6 Concurrent AI Tasks**: Summary, sentiment, keywords, questions, translation, categorization
- **Real-time Metrics**: Processing times, speedup ratios, efficiency gains
- **Business Applications**: Batch processing and workflow acceleration

### ï¿½ **4. Orchestrator-Worker System**
**File**: `orchestrator_worker.py` | **Port**: `7863`
- **Distributed Architecture**: Central orchestrator managing specialized AI workers
- **7 Specialized Workers**: Document Analyzer (2x), Sentiment, Translation, Summarization, Questions, Classification
- **Priority Task Queue**: Intelligent task scheduling and load balancing
- **Real-time Monitoring**: Worker performance tracking and system health analytics
- **Enterprise Features**: Fault tolerance, horizontal scaling, cost optimization

### ðŸ§ª **5. AI Evaluator-Optimizer System**
**File**: `evaluator_optimizer.py` | **Port**: `7864`
- **Multi-Metric Evaluation**: Accuracy, relevance, completeness, clarity assessment
- **Systematic Optimization**: Prompt engineering and parameter tuning
- **Performance Analytics**: Real-time metrics and optimization tracking
- **A/B Testing**: Scientific comparison of AI configurations

## ðŸ“‹ Prerequisites

- Python 3.8+
- OpenAI API key ([Get one here](https://platform.openai.com/api-keys))

## ðŸ› ï¸ Quick Start

### **Launch All Workflows**
```bash
# Terminal 1: Document Processing
python prompt_chaining.py
# Access at: http://localhost:7860

# Terminal 2: Request Routing  
python routing.py
# Access at: http://localhost:7861

# Terminal 3: Parallelization Demo
python parallelization.py
# Access at: http://localhost:7862

# Terminal 4: Orchestrator-Worker System
python orchestrator_worker.py
# Access at: http://localhost:7863

# Terminal 5: Evaluator-Optimizer System
python evaluator_optimizer.py
# Access at: http://localhost:7864
```

### **Single Workflow Setup**
1. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Set up OpenAI API key**
   ```env
   OPENAI_API_KEY=your-actual-api-key-here
   ```

3. **Run desired workflow**
   ```bash
   python [workflow_file].py
   ```

## ðŸŽ¯ Usage

### **Web Interface (Recommended)**
Each workflow provides a user-friendly Gradio interface:

- **ðŸ“„ Prompt Chaining**: Experience modular prompt chaining with step-by-step execution
- **ðŸŽ¯ Request Routing**: Enter customer requests for intelligent routing decisions  
- **âš¡ Parallelization**: Compare sequential vs parallel AI processing performance
- **ðŸŽ­ Orchestrator-Worker**: Distributed AI processing with specialized worker coordination
- **ðŸ§ª Evaluator-Optimizer**: Systematic AI testing and optimization dashboard

### **Features Available:**
- **Sample Data**: Pre-loaded examples for testing
- **Real-time Processing**: Live AI analysis and results
- **Performance Metrics**: Processing times and efficiency measurements
- **Export Options**: Copy results for further use

## ðŸ”„ Workflow Descriptions

### ðŸ“„ **Prompt Chaining Workflow**
Modular 4-step prompt chaining architecture:
1. **ðŸ“„ Document Summary**: Analyzes input text using specialized summarization prompts
2. **ðŸŽ¯ Main Points**: Extracts key insights through targeted analysis chains  
3. **ðŸ·ï¸ Smart Categorization**: Applies classification prompts with dependency tracking
4. **ðŸ’¡ Actionable Insights**: Generates recommendations through multi-step reasoning chains

**Key Features**: Step-by-step execution, partial chain capabilities, result tracking, composable workflows

### ðŸŽ¯ **Request Routing Workflow**
Intelligent 3-step routing system:
1. **ðŸŽ¯ Classification**: Analyzes request content and assigns appropriate category
2. **âš¡ Priority Assessment**: Determines urgency level and special handling needs
3. **ðŸ“‹ Action Planning**: Provides routing summary and recommended next steps

**Routing Categories**: Technical Support, Customer Service, Billing, Sales, Legal, HR, Veterans Affairs, Emergency

### âš¡ **Parallelization Workflow**
Performance optimization demonstration:
1. **ðŸ“Š Task Creation**: Generates 6 different AI analysis tasks
2. **ðŸ”„ Processing Modes**: Sequential vs Parallel execution comparison
3. **ðŸ“ˆ Performance Analysis**: Real-time metrics showing speedup and efficiency gains

### ï¿½ **Evaluator-Optimizer Workflow**
Advanced AI evaluation and optimization system:
1. **ðŸ§ª Test Case Creation**: Define input-output pairs for systematic AI testing
2. **ï¿½ Multi-Metric Assessment**: Evaluate accuracy, relevance, completeness, and clarity
3. **ðŸŽ¯ Systematic Optimization**: Test multiple prompt variations and parameter configurations
4. **ï¿½ Performance Analytics**: Track improvements and generate optimization recommendations

**Optimization Focus Areas**: Speed & Cost, Quality & Accuracy, Balanced Performance

## ðŸ“ Project Structure

```
ai-workflow-anthropic/
â”œâ”€â”€ prompt_chaining.py          # Modular prompt chaining workflow
â”œâ”€â”€ routing.py                  # Intelligent request routing  
â”œâ”€â”€ parallelization.py          # Concurrent AI processing demonstration
â”œâ”€â”€ orchestrator_worker.py      # Distributed orchestrator-worker system
â”œâ”€â”€ evaluator_optimizer.py      # AI evaluation and optimization system
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env                       # Environment variables (create this)
â”œâ”€â”€ .gitignore                # Git ignore file
â”œâ”€â”€ README.md                 # Main project documentation
â”œâ”€â”€ ROUTING_README.md         # Routing workflow details
â”œâ”€â”€ PARALLELIZATION_README.md # Parallelization documentation
â”œâ”€â”€ ORCHESTRATOR_README.md    # Orchestrator-worker pattern details
â”œâ”€â”€ EVALUATOR_README.md       # Evaluation-optimization documentation
â””â”€â”€ sample_business_report.txt # Sample document for testing
```

## ðŸŽ­ Orchestrator-Worker Architecture Deep Dive

The orchestrator-worker pattern represents a sophisticated distributed AI processing system designed for enterprise-scale applications.

### ðŸ—ï¸ **System Architecture**

**ðŸŽ­ Central Orchestrator:**
- Task queue management with priority-based scheduling
- Dynamic worker allocation and load balancing
- Fault tolerance and error handling
- Real-time performance monitoring and analytics
- Thread pool management for concurrent execution

**ðŸ‘¥ Specialized Worker Pool:**
```
ðŸ“„ Document Analyzer (2x)    - Comprehensive document analysis and insights
ðŸ˜Š Sentiment Analyzer (1x)   - Emotional tone and sentiment detection  
ðŸŒ Translator (1x)           - Multi-language translation services
ðŸ“ Summarizer (1x)           - Intelligent text summarization
â“ Question Generator (1x)    - Contextual question creation
ðŸ“‚ Category Classifier (1x)  - Content categorization and tagging
```

### âš¡ **Key Advantages**

**Scalability & Performance:**
- **Horizontal Scaling**: Add/remove workers dynamically based on demand
- **Parallel Processing**: Multiple tasks execute simultaneously across workers
- **Resource Optimization**: Efficient utilization of AI API rate limits
- **Load Distribution**: Intelligent task routing to available workers

**Reliability & Monitoring:**
- **Fault Isolation**: Worker failures don't affect the entire system
- **Health Monitoring**: Real-time worker status and performance tracking
- **Task Recovery**: Failed tasks can be redistributed to healthy workers
- **Performance Analytics**: Detailed metrics on processing times and success rates

**Enterprise Features:**
- **Priority Queuing**: Critical tasks processed first
- **Worker Specialization**: Optimized prompts and configurations per task type
- **Workflow Orchestration**: Coordinate complex multi-step AI processes
- **Cost Management**: Track and optimize AI API usage across the system

## ðŸ¤ Business Applications

This AI workflow system can be applied to:

**Prompt Chaining Applications:**
- **ðŸ“Š Business Reports**: Automated analysis and strategic insight extraction
- **ðŸ“‹ Policy Documents**: Compliance review and action item identification
- **ðŸ“„ Contract Analysis**: Risk assessment and key terms extraction
- **ðŸ“ˆ Market Research**: Data analysis and strategic recommendations

**Intelligent Routing Applications:**
- **ï¿½ Customer Support**: Automated ticket classification and priority assignment
- **ï¿½ Email Management**: Smart sorting and department routing
- **ðŸŽ¯ Lead Qualification**: Sales inquiry categorization and follow-up routing
- **ðŸ¥ Healthcare Triage**: Patient inquiry routing and urgency assessment

**System Optimization Applications:**
- **ðŸ§ª A/B Testing**: Prompt variation testing and performance optimization
- **ðŸ“ˆ Performance Monitoring**: Real-time AI system evaluation and improvement
- **ðŸŽ¯ Quality Assurance**: Automated testing of AI outputs and accuracy tracking
- **âš¡ Resource Optimization**: Processing efficiency and cost optimization

**Distributed Processing Applications:**
- **ðŸŽ­ Enterprise Document Processing**: Large-scale document analysis with specialized workers
- **ðŸ¥ Healthcare Systems**: Coordinated analysis of patient records, medical imaging, and research data
- **ðŸŽ–ï¸ Veterans Affairs**: Distributed processing of claims, appeals, medical records, and benefits analysis
- **ðŸ“Š Financial Services**: Parallel risk analysis, compliance checking, and fraud detection
- **ðŸ“ž Contact Centers**: Real-time analysis of support tickets, chat logs, and customer feedback
- **ðŸ” Legal Discovery**: Coordinated review of legal documents with specialized analysis workers
- **âš¡ Resource Optimization**: Processing efficiency and cost optimization

## ðŸ›¡ï¸ Security Notes

- Keep your `.env` file private (it's already in `.gitignore`)
- Never commit API keys to version control
- Consider using environment variables in production

## ðŸ“š Dependencies

- `openai>=1.0.0` - OpenAI API client
- `gradio>=4.0.0` - Web interface framework  
- `python-dotenv>=1.0.0` - Environment variable loading
- `PyPDF2>=3.0.0` - PDF document processing
- `python-docx>=0.8.11` - Microsoft Word document processing
